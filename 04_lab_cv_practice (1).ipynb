{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5dfc8bae",
      "metadata": {
        "id": "5dfc8bae"
      },
      "source": [
        "# Лабораторная работа №4\n",
        "\n",
        "ФИО:  Поцелуев Андрей Александрович\n",
        "Группа: БИВТ-20-1\n",
        "\n",
        "Отправлять можно следующими способами (**обязательно указать свое ФИО и группу в каком-либо виде**):\n",
        "1. Создать **приватный** репозиторий на github, добавить меня по нику (l3lush) в Collaborators (Settings -> Collaborators -> Add people)\n",
        "2. Отправить заполненный ноутбук мне на почту avmysh@gmail.com, либо m1603956@edu.misis.ru\n",
        "3. Отправить заполненный ноутбук мне в тг @l3lush.\n",
        "\n",
        "**Deadline**:\n",
        "- hard -- **04.06.2023 23:59** (дедлайн теперь один)\n",
        "\n",
        "\n",
        "**Что необходимо сделать** (можете вдохновляться ноутбуками для семинара, они должны помочь):\n",
        "1. Загрузить датасет (вариант смотреть [здесь](https://docs.google.com/spreadsheets/d/1pFk1qZJtMrV8GWUmdSjV5Kz6JnFdBQDShErFZ337FDc/edit?usp=sharing))\n",
        "2. Описать кратенько словами датасет, описать поставку задачи, что от чего отличаем, привести примеры картинок (картинки можно визуализировать после шага 3, когда у вас будет красивый датасет).\n",
        "3. Оформить датасет в виде объекта класса Dataset из PyTorch (обязательно надо сделать препроцессинг данных: нормализовать данные, добавить аугментации к данным и пр.).\n",
        "4. Оформить датасет из шага 3 в Dataloader.\n",
        "5. Реализовать архитектуру собственной нейросети и натренировать ее на датасете (можно не обучать 1000 эпох, достаточно 10 эпох, но чтобы метрики начали улучшаться).\n",
        "6. Обучить нейросеть, используя Transfer Learning. Модель можно выбрать на свой вкус (список всех моделей, доступных в torchvision есть [тут](https://pytorch.org/vision/stable/models.html)).\n",
        "7. Посчитать метрики качества финальной модели, сделать выводы.\n",
        "\n",
        "**Замечание**\n",
        "Если понимаете, что данные слишком много весят, или с датасетом что-то не так, можете брать любой другой.\n",
        "\n",
        "P.S. Чтобы не ждать века, тренируйте модели на Colab с использованием GPU (Runtime -> Change runtime type -> GPU)\n",
        "P.S.S. Сохраняйте вывод ячеек и пушьте вместе с ним, в противном случае я не смогу нормально проверить все работы, если буду запускать все ноутбуки и ждать обучение моделей"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-04T21:52:48.963455200Z",
          "start_time": "2023-06-04T21:52:48.952929500Z"
        },
        "id": "RB9oUQBLRNFw"
      },
      "id": "RB9oUQBLRNFw"
    },
    {
      "cell_type": "markdown",
      "id": "00cd0432",
      "metadata": {
        "id": "00cd0432"
      },
      "source": [
        "# Шаги 1-3"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### cifar100\n",
        "\n",
        "The CIFAR-100 dataset consists of 60000 32x32 colour images in 100 classes, with 600 images per class. There are 500 training images and 100 testing images per class. There are 50000 training images and 10000 test images. The 100 classes are grouped into 20 superclasses. There are two labels per image - fine label (actual class) and coarse label (superclass)."
      ],
      "metadata": {
        "collapsed": false,
        "id": "BLdpS8RmRNFx"
      },
      "id": "BLdpS8RmRNFx"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "9518c759",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-04T21:52:49.883029200Z",
          "start_time": "2023-06-04T21:52:48.963455200Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9518c759",
        "outputId": "76de38eb-8828-4735-a934-b1766bd15b52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "from torchvision.datasets import CIFAR100\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "    # transforms.Resize((256,256)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    # transforms.Resize((256,256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "cifar_train = CIFAR100(root='./data', train=True, download=True, transform=train_transforms)\n",
        "cifar_test = CIFAR100(root='./data', train=False, download=True, transform=test_transforms)\n",
        "\n",
        "train_dataloader = DataLoader(cifar_train, batch_size=16, shuffle=True)\n",
        "test_dataloader = DataLoader(cifar_test, batch_size=16, shuffle=False)\n",
        "\n",
        "dataset_sizes = {\n",
        "    'train': len(cifar_train),\n",
        "    'test': len(cifar_test)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class names: ['apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', 'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', 'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur', 'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', 'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion', 'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse', 'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear', 'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine', 'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose', 'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake', 'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table', 'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout', 'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman', 'worm']\n"
          ]
        }
      ],
      "source": [
        "class_names = cifar_test.classes\n",
        "print(f'Class names: {class_names}')"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-04T21:52:49.887788300Z",
          "start_time": "2023-06-04T21:52:49.885144300Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_Zq1p_4RNFy",
        "outputId": "5d450b09-a549-4640-f3c6-8579f513526e"
      },
      "id": "n_Zq1p_4RNFy"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device = torch.device(\"mps\" if torch.backends.mps.is_available() else device)\n",
        "device"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-04T21:52:49.893596300Z",
          "start_time": "2023-06-04T21:52:49.888845800Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stlU4fuPRNFz",
        "outputId": "beef902d-ea94-4fad-f7ed-d34aa4c1740c"
      },
      "id": "stlU4fuPRNFz"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "outputs": [],
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        for phase in ['train', 'test']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            current_dataloader = train_dataloader\n",
        "            if phase == 'test':\n",
        "                current_dataloader = test_dataloader\n",
        "\n",
        "\n",
        "            for inputs, labels in current_dataloader:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.float() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            if phase == 'test' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best test Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model\n",
        "\n",
        "def visualize_model(model, num_images=6, bias=0):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    bias_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(test_dataloader):\n",
        "            inputs = inputs.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                bias_so_far += 1\n",
        "                if bias_so_far < bias:\n",
        "                    continue\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-04T21:52:50.070980800Z",
          "start_time": "2023-06-04T21:52:50.069431600Z"
        },
        "id": "fKtYCneuRNFz"
      },
      "id": "fKtYCneuRNFz"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/4\n",
            "----------\n",
            "train Loss: 3.1021 Acc: 0.2506\n",
            "test Loss: 2.5418 Acc: 0.3509\n",
            "\n",
            "Epoch 1/4\n",
            "----------\n",
            "train Loss: 2.1376 Acc: 0.4448\n",
            "test Loss: 2.3114 Acc: 0.4077\n",
            "\n",
            "Epoch 2/4\n",
            "----------\n",
            "train Loss: 1.3556 Acc: 0.6520\n",
            "test Loss: 2.0474 Acc: 0.4698\n",
            "\n",
            "Epoch 3/4\n",
            "----------\n",
            "train Loss: 1.2108 Acc: 0.6916\n",
            "test Loss: 2.0220 Acc: 0.4764\n",
            "\n",
            "Epoch 4/4\n",
            "----------\n",
            "train Loss: 1.0928 Acc: 0.7278\n",
            "test Loss: 2.0086 Acc: 0.4809\n",
            "\n",
            "Training complete in 3m 47s\n",
            "Best test Acc: 0.480900\n"
          ]
        }
      ],
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Conv2d(3, 16, 3, padding=2),\n",
        "    nn.ReLU(),\n",
        "    nn.Conv2d(16, 32, 3, padding=2),\n",
        "    nn.ReLU(),\n",
        "    nn.Conv2d(32, 64, 3, padding=2),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(2, 2),\n",
        "\n",
        "\n",
        "    nn.BatchNorm2d(64),\n",
        "    # nn.Softmax2d(),\n",
        "\n",
        "    nn.Flatten(),\n",
        "\n",
        "    nn.Linear(23104, 1024),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(1024, 100),\n",
        ")\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer_ft = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=2, gamma=0.1)\n",
        "model_fitted = train_model(model, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=5)"
      ],
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "ExecuteTime": {
          "end_time": "2023-06-04T21:55:03.887917800Z",
          "start_time": "2023-06-04T21:52:50.074688200Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Gplzhe9RNF0",
        "outputId": "68d100e8-dce7-4c85-dafe-a415bafc20ad"
      },
      "id": "_Gplzhe9RNF0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Шаг 6"
      ],
      "metadata": {
        "collapsed": false,
        "id": "lx4rL-enRNF0"
      },
      "id": "lx4rL-enRNF0"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "pretrained_train_transforms = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "pretrained_test_transforms = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "pretrained_cifar_train = CIFAR100(root='./data', train=True, download=True, transform=pretrained_train_transforms)\n",
        "pretrained_cifar_test = CIFAR100(root='./data', train=False, download=True, transform=pretrained_test_transforms)\n",
        "\n",
        "pretrained_train_dataloader = DataLoader(pretrained_cifar_train, batch_size=16, shuffle=True)\n",
        "pretrained_test_dataloader = DataLoader(pretrained_cifar_test, batch_size=16, shuffle=False)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-04T21:55:05.041795400Z",
          "start_time": "2023-06-04T21:55:04.118885100Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sItyQ5t7RNF0",
        "outputId": "64209eff-ac63-4ccc-9cb5-f709cdcf58da"
      },
      "id": "sItyQ5t7RNF0"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "outputs": [],
      "source": [
        "def train_pretrained(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        for phase in ['train', 'test']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            current_dataloader = pretrained_train_dataloader\n",
        "            if phase == 'test':\n",
        "                current_dataloader = pretrained_test_dataloader\n",
        "\n",
        "\n",
        "            for inputs, labels in current_dataloader:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.float() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            if phase == 'test' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best test Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-04T21:55:05.052263100Z",
          "start_time": "2023-06-04T21:55:05.047515600Z"
        },
        "id": "h8kUeLJiRNF1"
      },
      "id": "h8kUeLJiRNF1"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 244MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "512\n"
          ]
        }
      ],
      "source": [
        "resnet_model = models.resnet18(weights='DEFAULT')\n",
        "num_features = resnet_model.fc.in_features\n",
        "\n",
        "resnet_model.fc = nn.Linear(num_features, 100)\n",
        "\n",
        "print(num_features)\n",
        "\n",
        "model_ft = resnet_model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=2, gamma=0.1)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-04T21:56:55.072055200Z",
          "start_time": "2023-06-04T21:56:54.929536800Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZX5qcJRvRNF1",
        "outputId": "bd1f9020-7e9d-4e2e-98b5-3d95bae71735"
      },
      "id": "ZX5qcJRvRNF1"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/6\n",
            "----------\n",
            "train Loss: 1.7238 Acc: 0.5559\n",
            "test Loss: 0.8728 Acc: 0.7416\n",
            "\n",
            "Epoch 1/6\n",
            "----------\n",
            "train Loss: 0.8586 Acc: 0.7504\n",
            "test Loss: 0.7714 Acc: 0.7690\n",
            "\n",
            "Epoch 2/6\n",
            "----------\n",
            "train Loss: 0.5642 Acc: 0.8383\n",
            "test Loss: 0.6428 Acc: 0.8026\n",
            "\n",
            "Epoch 3/6\n",
            "----------\n",
            "train Loss: 0.5001 Acc: 0.8566\n",
            "test Loss: 0.6334 Acc: 0.8040\n",
            "\n",
            "Epoch 4/6\n",
            "----------\n",
            "train Loss: 0.4656 Acc: 0.8694\n",
            "test Loss: 0.6265 Acc: 0.8067\n",
            "\n",
            "Epoch 5/6\n",
            "----------\n",
            "train Loss: 0.4605 Acc: 0.8699\n",
            "test Loss: 0.6235 Acc: 0.8076\n",
            "\n",
            "Epoch 6/6\n",
            "----------\n",
            "train Loss: 0.4555 Acc: 0.8718\n",
            "test Loss: 0.6235 Acc: 0.8074\n",
            "\n",
            "Training complete in 29m 11s\n",
            "Best test Acc: 0.807600\n"
          ]
        }
      ],
      "source": [
        "fitted_resnet = train_pretrained(resnet_model, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=7)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-04T22:35:00.793376300Z",
          "start_time": "2023-06-04T22:18:17.263659300Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEKs99RaRNF1",
        "outputId": "6edee6b6-93ad-4590-991c-0e7190151e73"
      },
      "id": "hEKs99RaRNF1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Выводы\n",
        "\n",
        "В ходе работы была построена и натренирована модель, в качестве датасета был выбран CIFAR100 (в моем варианте все на китайском, я не разобрался и выбрал вариант из torchvision). Модель показала вполне хорошие показатели точности."
      ],
      "metadata": {
        "collapsed": false,
        "id": "7PT4YhgnRNF1"
      },
      "id": "7PT4YhgnRNF1"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}